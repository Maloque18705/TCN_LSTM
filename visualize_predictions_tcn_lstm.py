"""
Simple prediction visualization script based on trained model.

Usage:
    python visualize_predictions_tcn_lstm.py outputs/tcn_lstm/5p/run_TCN_LSTM_...
    python visualize_predictions_tcn_lstm.py outputs/tcn_lstm/5p/run_TCN_LSTM_... --num-samples 20
"""

import argparse
import sys
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

from Data.dataloader import DataLoader, DataProcess
from Data import config
from Model.tcn_lstm import TCN_LSTM, ResidualBlock


def parse_args():
    p = argparse.ArgumentParser(description="Visualize predictions from trained TCN-LSTM model")
    p.add_argument("run_dir", type=str, help="Path to run directory (e.g., outputs/tcn_lstm/5p/run_XXX)")
    p.add_argument("--num-samples", type=int, default=10, help="Number of samples to visualize")
    p.add_argument("--save", action="store_true", help="Save plots instead of displaying")
    return p.parse_args()


def main():
    args = parse_args()
    run_dir = Path(args.run_dir)

    if not run_dir.exists():
        print(f"‚ùå Run directory not found: {run_dir}")
        sys.exit(1)

    print(f"üìÇ Using run directory: {run_dir}")

    # 1Ô∏è‚É£ Load model
    model_path = run_dir / "model_saved.keras"
    if not model_path.exists():
        print(f"‚ùå Model not found: {model_path}")
        sys.exit(1)

    print(f"üì¶ Loading model from: {model_path}")
    
    # C·∫ßn thi·∫øt ƒë·ªÉ Keras bi·∫øt 'TCN_LSTM' v√† 'ResidualBlock' l√† g√¨ khi t·∫£i
    custom_objects = {'TCN_LSTM': TCN_LSTM, 'ResidualBlock': ResidualBlock}
    
    try:
        # Th·ª≠ t·∫£i v·ªõi custom_objects (c√°ch an to√†n nh·∫•t)
        model = tf.keras.models.load_model(str(model_path), custom_objects=custom_objects)
        print(f"‚úÖ Model loaded successfully with custom_objects!")
    except Exception as e:
        print(f"‚ùå Failed to load model: {e}")
        print("M·∫πo: ƒê·∫£m b·∫£o file 'Model/tcn_lstm.py' ƒë√£ ƒë∆∞·ª£c s·ª≠a (v·ªõi **kwargs v√† get_config) v√† n·∫±m trong PYTHONPATH.")
        sys.exit(1)


    # 2Ô∏è‚É£ Load scaler values
    scaler_path = run_dir / "scaler_values.npy"
    if not scaler_path.exists():
        print(f"‚ùå Scaler not found: {scaler_path}")
        sys.exit(1)

    min_scaler, max_scaler = np.load(scaler_path)
    print(f"üìä Scaler loaded: min={min_scaler:.6f}, max={max_scaler:.6f}")

    # 3Ô∏è‚É£ Load original data
    print(f"üìÇ Loading data from: {config.FOLDER_PATH}")
    dl = DataLoader(folder_path=config.FOLDER_PATH)
    try:
        final_array = dl.read_data()
        print(f"‚úÖ Data loaded: {final_array.shape}")
    except Exception as e:
        print(f"‚ùå Failed to load data: {e}")
        sys.exit(1)

    dp = DataProcess()
    Data1 = dp.extract_from_sensor(final_array, case_index=0)
    print(f"‚úÖ Sensor data extracted: {Data1.shape}")

    # 4Ô∏è‚É£ Sample random segments from Data1
    num_samples = args.num_samples
    time_steps = config.INPUT_STEPS + config.OUTPUT_STEPS  # e.g., 100 + 5 = 105

    # Ensure we have enough data
    if len(Data1) < time_steps:
        print(f"‚ùå Not enough data: {len(Data1)} < {time_steps}")
        sys.exit(1)

    # Random sampling
    start_indices = np.random.randint(0, len(Data1) - time_steps, num_samples)
    samples = np.array([Data1[i:i + time_steps] for i in start_indices])
    print(f"‚úÖ Sampled {num_samples} segments: {samples.shape}")

    # 5Ô∏è‚É£ Split into X (input) and y_true (ground truth)
    X = samples[:, :config.INPUT_STEPS]  # First 100 timesteps
    y_true = samples[:, config.INPUT_STEPS:]  # Last 5 timesteps

    print(f"üìä X (input): {X.shape}")
    print(f"üìä y_true (ground truth): {y_true.shape}")

    # 6Ô∏è‚É£ Normalize X
    denom = max_scaler - min_scaler
    if denom == 0:
        denom = 1  # Avoid division by zero

    X_normalized = (X - min_scaler) / denom
    X_input = X_normalized.reshape((X_normalized.shape[0], X_normalized.shape[1], 1))
    print(f"‚úÖ Normalized X_input: {X_input.shape}")

    # 7Ô∏è‚É£ Predict
    print(f"üîÆ Predicting...")
    y_pred = model.predict(X_input, verbose=0)
    print(f"‚úÖ Predictions done: {y_pred.shape}")

    # 8Ô∏è‚É£ Inverse transform predictions to original scale
    y_pred_real = y_pred * denom + min_scaler
    print(f"‚úÖ Predictions converted to original scale")

    # 9Ô∏è‚É£ Visualize
    # n_steps = config.INPUT_STEPS # (Kh√¥ng c·∫ßn d√πng)
    
    # 1. THAY ƒê·ªîI: T·∫°o tr·ª•c x m·ªõi (0, 1, 2, 3, 4)
    time_future_adj = np.arange(config.OUTPUT_STEPS)

    if args.save:
        plot_dir = run_dir / "predictions"
        plot_dir.mkdir(exist_ok=True)
        print(f"üíæ Saving plots to: {plot_dir}")

    for i in range(num_samples):
        # 2. THAY ƒê·ªîI: Thu nh·ªè figure
        plt.figure(figsize=(10, 4))

        # 3. THAY ƒê·ªîI: X√≥a b·ªè ph·∫ßn v·∫Ω "Past Data (Input)"
        # Plot past data (input) -> ƒê√É B·ªä X√ìA
        # time_input = np.arange(n_steps)
        # plt.plot(time_input, X[i], 's-', ...)

        # 4. THAY ƒê·ªîI: D√πng tr·ª•c x m·ªõi (time_future_adj)
        # Plot actual future (ground truth)
        plt.plot(time_future_adj, y_true[i], 'o-', label="Actual Future (Ground Truth)",
                 color='blue', markersize=5, linewidth=2)

        # 5. THAY ƒê·ªîI: D√πng tr·ª•c x m·ªõi (time_future_adj)
        # Plot predicted future
        plt.plot(time_future_adj, y_pred_real[i], 'D--', label="Predicted Future",
                 color='red', markersize=5, linewidth=2)

        # 6. THAY ƒê·ªîI: X√≥a b·ªè c√°c ƒë∆∞·ªùng n·ªëi
        # Connect last point of past to future -> ƒê√É B·ªä X√ìA
        # plt.plot([n_steps - 1, n_steps], ...)
        # plt.plot([n_steps - 1, n_steps], ...)

        # Formatting
        plt.axhline(0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)
        # 7. THAY ƒê·ªîI: X√≥a b·ªè ƒë∆∞·ªùng ph√¢n c√°ch (axvline)
        # plt.axvline(n_steps, ...) -> ƒê√É B·ªä X√ìA

        # 8. THAY ƒê·ªîI: C·∫≠p nh·∫≠t nh√£n X v√† Ti√™u ƒë·ªÅ
        plt.xlabel("Future Time Step", fontsize=12)
        plt.ylabel("Value", fontsize=12)
        
        # 9. THAY ƒê·ªîI: C·∫≠p nh·∫≠t ti√™u ƒë·ªÅ cho TCN-LSTM
        plt.title(f"Future Prediction - Sample {i+1}/{num_samples} TCN-LSTM - Missing {config.OUTPUT_STEPS}%", fontsize=14)
        
        # 10. THAY ƒê·ªîI: Di chuy·ªÉn ch√∫ gi·∫£i (legend)
        plt.legend(loc='upper right', fontsize=10) # <-- THAY ƒê·ªîI T·∫†I ƒê√ÇY
        
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        if args.save:
            save_path = plot_dir / f"prediction_sample_{i+1:03d}.png"
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"üíæ Saved: {save_path.name}")
        else:
            plt.show()

    if args.save:
        print(f"‚úÖ All {num_samples} plots saved to: {plot_dir}")
    else:
        print(f"‚úÖ Displayed {num_samples} prediction plots")


if __name__ == "__main__":
    main()